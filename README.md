# ğŸ¤– OrÃ¡culo RAG

OrÃ¡culo Ã© uma aplicaÃ§Ã£o web interativa construÃ­da com Streamlit que implementa RAG (Retrieval-Augmented Generation) com memÃ³ria vetorial. Permite conversar com modelos de IA (OpenAI e Groq) sobre diferentes tipos de documentos usando busca semÃ¢ntica para recuperar informaÃ§Ãµes relevantes.

## âœ¨ Funcionalidades

- **RAG com MemÃ³ria Vetorial:**
  - Armazenamento vetorial com ChromaDB
  - Busca semÃ¢ntica de informaÃ§Ãµes relevantes
  - RecuperaÃ§Ã£o dos 8 chunks mais relevantes para cada pergunta
  - PersistÃªncia de sessÃµes de conversa

- **MÃºltiplos tipos de documentos suportados:**
  - ğŸ“„ Sites (URLs)
  - ğŸ¥ VÃ­deos do YouTube
  - ğŸ“‘ Arquivos PDF
  - ğŸ“Š Arquivos CSV
  - ğŸ“ Arquivos de texto (TXT)

- **MÃºltiplos provedores de IA:**
  - OpenAI (GPT-4o, GPT-4o-mini)
  - Groq (Llama 3.1 70B, Mixtral 8x7B)

- **Interface intuitiva:**
  - Chat interativo com histÃ³rico de conversas (Ãºltimos 4 turnos)
  - Sidebar para configuraÃ§Ã£o e upload
  - Streaming de respostas em tempo real
  - Limpeza de memÃ³ria do chat
  - RemoÃ§Ã£o de sessÃµes e vetores

## ğŸ“‹ PrÃ©-requisitos

- Python 3.8 ou superior
- API Keys:
  - OpenAI API Key (para modelos OpenAI e embeddings)
  - Groq API Key (para modelos Groq)

## ğŸš€ InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/DSagentpy/oraculo.git
cd oraculo
```

2. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

## ğŸ“¦ DependÃªncias

O projeto utiliza as seguintes bibliotecas principais:

- `streamlit` - Framework para aplicaÃ§Ãµes web
- `langchain` - Framework para aplicaÃ§Ãµes com LLMs
- `langchain-community` - Loaders de documentos da comunidade
- `langchain-groq` - IntegraÃ§Ã£o com Groq
- `langchain-openai` - IntegraÃ§Ã£o com OpenAI e embeddings
- `chromadb` - Banco de dados vetorial (via langchain-community)
- `fake_useragent` - GeraÃ§Ã£o de User-Agents aleatÃ³rios
- `pypdf` - Processamento de PDFs
- `bs4` - Parsing de HTML
- `unstructured` - Processamento de documentos nÃ£o estruturados
- `python-dotenv` - Gerenciamento de variÃ¡veis de ambiente

## ğŸ¯ Como Usar

1. **Inicie a aplicaÃ§Ã£o:**
```bash
streamlit run app.py
```

2. **Configure o OrÃ¡culo:**
   - Na sidebar, selecione o tipo de arquivo (Site, Youtube, PDF, Csv ou Txt)
   - Se for Site ou Youtube, forneÃ§a a URL
   - Se for PDF, CSV ou TXT, faÃ§a upload do arquivo
   - Selecione o provedor (OpenAI ou Groq)
   - Escolha o modelo desejado
   - Insira sua OpenAI API Key (necessÃ¡ria para embeddings, mesmo usando Groq)
   - Clique em "ğŸš€ Inicializar OrÃ¡culo"

3. **Comece a conversar:**
   - Digite suas perguntas no campo de chat
   - O OrÃ¡culo buscarÃ¡ informaÃ§Ãµes relevantes no documento usando busca semÃ¢ntica
   - A resposta serÃ¡ gerada com base no contexto recuperado
   - Use "ğŸ§¹ Limpar HistÃ³rico" para resetar o histÃ³rico de conversas
   - Use "ğŸ—‘ï¸ Remover SessÃ£o" para remover a sessÃ£o e os vetores armazenados

## ğŸ—ï¸ Arquitetura RAG

O OrÃ¡culo implementa RAG (Retrieval-Augmented Generation) da seguinte forma:

1. **Carregamento de Documentos:** Os documentos sÃ£o carregados usando loaders especÃ­ficos
2. **DivisÃ£o em Chunks:** O texto Ã© dividido em chunks de 2000 caracteres com overlap de 500
3. **GeraÃ§Ã£o de Embeddings:** Cada chunk Ã© convertido em vetor usando OpenAI Embeddings
4. **Armazenamento Vetorial:** Os vetores sÃ£o armazenados no ChromaDB
5. **RecuperaÃ§Ã£o:** Para cada pergunta, os 8 chunks mais relevantes sÃ£o recuperados
6. **GeraÃ§Ã£o:** O LLM gera a resposta usando o contexto recuperado e o histÃ³rico da conversa

## ğŸ“ Estrutura do Projeto

```
oraculo/
â”œâ”€â”€ app.py              # AplicaÃ§Ã£o principal Streamlit
â”œâ”€â”€ rag.py              # LÃ³gica RAG (inicializaÃ§Ã£o e geraÃ§Ã£o de respostas)
â”œâ”€â”€ config.py           # ConfiguraÃ§Ãµes (modelos, tipos de arquivos)
â”œâ”€â”€ loaders.py          # FunÃ§Ãµes para carregar diferentes tipos de documentos
â”œâ”€â”€ vectorstore.py      # CriaÃ§Ã£o e gerenciamento do vectorstore
â”œâ”€â”€ session.py          # Gerenciamento de sessÃµes e persistÃªncia
â”œâ”€â”€ requirements.txt    # DependÃªncias do projeto
â””â”€â”€ README.md           # Este arquivo
```

## ğŸ”§ Arquivos Principais

### `app.py`
AplicaÃ§Ã£o principal que contÃ©m:
- Interface Streamlit
- Gerenciamento de estado (histÃ³rico de chat, orÃ¡culo)
- InicializaÃ§Ã£o de modelos de IA
- Interface de chat interativa com streaming

### `rag.py`
MÃ³dulo com a lÃ³gica RAG:
- `inicializar_oraculo()` - Carrega documento, cria vectorstore e inicializa o orÃ¡culo
- `stream_resposta()` - Gera respostas usando RAG com streaming
- `formatar_historico()` - Formata o histÃ³rico de conversas (Ãºltimos 4 turnos)
- `carregar_arquivo()` - Roteia para o loader apropriado

### `config.py`
ConfiguraÃ§Ãµes centralizadas:
- Tipos de arquivos suportados
- Modelos disponÃ­veis por provedor
- Limite de histÃ³rico de conversas

### `loaders.py`
MÃ³dulo com funÃ§Ãµes para carregar diferentes tipos de documentos:
- `carregar_site()` - Carrega conteÃºdo de URLs (com retry e User-Agents aleatÃ³rios)
- `carregar_youtube()` - Extrai transcriÃ§Ãµes de vÃ­deos do YouTube
- `carregar_pdf()` - Processa arquivos PDF
- `carregar_csv()` - Processa arquivos CSV
- `carregar_txt()` - Processa arquivos de texto

### `vectorstore.py`
CriaÃ§Ã£o do vectorstore:
- `criar_vectorstore()` - Divide documentos, gera embeddings e cria vectorstore ChromaDB

### `session.py`
Gerenciamento de sessÃµes:
- `criar_sessao()` - Cria uma nova sessÃ£o com ID Ãºnico
- `remover_sessao()` - Remove sessÃ£o e limpa vetores armazenados

## ğŸ’¡ Exemplos de Uso

### Carregar um site
1. Selecione "Site" como tipo de arquivo
2. Digite a URL: `https://exemplo.com`
3. Configure o modelo e API Key
4. Inicialize o OrÃ¡culo
5. FaÃ§a perguntas sobre o conteÃºdo do site

### Carregar um vÃ­deo do YouTube
1. Selecione "Youtube" como tipo de arquivo
2. Digite a URL do vÃ­deo
3. O OrÃ¡culo extrairÃ¡ a transcriÃ§Ã£o automaticamente
4. FaÃ§a perguntas sobre o conteÃºdo do vÃ­deo

### Carregar um PDF
1. Selecione "PDF" como tipo de arquivo
2. FaÃ§a upload do arquivo PDF
3. O conteÃºdo serÃ¡ processado e indexado vetorialmente
4. FaÃ§a perguntas sobre o conteÃºdo do PDF

## âš™ï¸ ConfiguraÃ§Ã£o

O OrÃ¡culo suporta os seguintes modelos:

**OpenAI:**
- `gpt-4o-mini`
- `gpt-4o`

**Groq:**
- `llama-3.1-70b-versatile`
- `mixtral-8x7b-32768`

**Embeddings:**
- OpenAI Embeddings (usado para todos os casos)

**ParÃ¢metros RAG:**
- Tamanho do chunk: 2000 caracteres
- Overlap: 500 caracteres
- NÃºmero de chunks recuperados (k): 8
- HistÃ³rico de conversas: Ãºltimos 4 turnos

## ğŸ”’ SeguranÃ§a

- As API Keys sÃ£o inseridas como campos de senha (nÃ£o sÃ£o exibidas)
- Arquivos temporÃ¡rios sÃ£o criados durante o processamento e podem ser limpos apÃ³s o uso
- SessÃµes sÃ£o isoladas por ID Ãºnico
- Vetores sÃ£o armazenados localmente no diretÃ³rio `chromadb/`

## ğŸ› SoluÃ§Ã£o de Problemas

- **Erro ao carregar site:** O OrÃ¡culo tenta carregar o site atÃ© 5 vezes com User-Agents aleatÃ³rios. Se falhar, verifique se a URL estÃ¡ correta e acessÃ­vel.
- **Erro de API Key:** Certifique-se de que a OpenAI API Key estÃ¡ correta (necessÃ¡ria para embeddings). A Groq API Key sÃ³ Ã© necessÃ¡ria se estiver usando modelos Groq.
- **MemÃ³ria insuficiente:** Para documentos muito grandes, considere dividir em partes menores.
- **SessÃ£o nÃ£o removida:** Use o botÃ£o "ğŸ—‘ï¸ Remover SessÃ£o" para limpar os vetores armazenados.

## ğŸ“ Notas

- O histÃ³rico de conversas mantÃ©m os Ãºltimos 4 turnos para contexto
- Cada inicializaÃ§Ã£o do OrÃ¡culo cria uma nova sessÃ£o e limpa o histÃ³rico anterior
- Os vetores sÃ£o persistidos no diretÃ³rio `chromadb/` (nÃ£o versionado no git)
- O sistema usa streaming para respostas em tempo real

## ğŸ¤ Contribuindo

Sinta-se Ã  vontade para abrir issues ou pull requests para melhorias!

## ğŸ“„ LicenÃ§a

Este projeto Ã© de uso educacional.

---
